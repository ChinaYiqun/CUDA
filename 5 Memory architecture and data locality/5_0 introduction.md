# GPU的片上内存架构与数据访问优化

## 引言
到目前为止，我们已经学会了如何编写一个 CUDA 内核函数，以及如何通过大量线程配置和协调其执行。我们还研究了当前 GPU 硬件的计算架构，以及线程如何被安排在这个硬件上执行。

## 问题所在
在本章中，我们将重点关注 GPU 的片上内存架构，并开始研究如何组织和定位数据，以便由大量线程进行高效访问。到目前为止，我们研究的 CUDA 内核可能只能实现底层硬件潜在速度的一小部分。

## 性能瓶颈
这种糟糕的性能是因为通常使用片外 DRAM 实现的全局内存往往具有较长的访问延迟（数百个时钟周期）和有限的访问带宽。虽然有许多可供执行的线程理论上可以容忍长内存访问延迟，但人们很容易遇到这样一种情况，即全局内存访问路径中的流量拥塞阻止了除极少数线程之外的所有线程取得进展，从而导致流式多处理器（SM）中的一些内核空闲。

## 解决方案
为了规避这种拥塞，GPU 提供了许多额外的片上内存资源来访问数据，这些资源可以消除进出全局内存的大部分流量。

## 本章目标
在本章中，我们将研究使用不同的内存类型来提高 CUDA 内核的执行性能。