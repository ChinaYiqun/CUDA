## 5.6 内存使用对占用率的影响

回想在第4章“计算架构和调度”中，我们讨论了在SM上最大化线程占用率的重要性，以便能够容忍长时间操作的延迟。内核的内存使用在占用率调整中起着重要作用。虽然CUDA寄存器和共享内存在减少对全局内存的访问次数方面极其有效，但必须小心不要超出SM对这些内存的容量限制。每个CUDA设备提供的资源有限，这限制了给定应用程序可以同时驻留在每个SM中的线程数量。一般来说，每个线程所需的资源越多，可以驻留在每个SM中的线程数量就越少。

我们在第4章“计算架构和调度”中看到，寄存器使用可以成为占用率的限制因素。共享内存的使用也可以限制可以分配给每个SM的线程数量。例如，A100 GPU可以配置为每个SM拥有高达164 KB的共享内存，并支持每个SM最多2048个线程。因此，要使用所有2048个线程插槽，一个线程块平均不能使用超过(164 KB)/(2048 threads) = 82 B/thread的共享内存。在分块矩阵乘法示例中，每个块有TILE_WIDTH^2个线程，并为Mds使用TILE_WIDTH^2*4B的共享内存，为Nds使用TILE_WIDTH^2*4B的共享内存。因此，线程块平均使用(TILE_WIDTH^2*4B + TILE_WIDTH^2*4B) / (TILE_WIDTH^2 threads) = 8 B/thread的共享内存。因此，分块矩阵乘法内核的占用率不受共享内存的限制。

然而，考虑一个内核，其线程块使用32 KB的共享内存，每个线程块有256个线程。在这种情况下，内核平均使用(32 KB)/(256 threads) = 132 B/thread的共享内存。有了这样的共享内存使用，内核无法实现完全占用率。每个SM最多可以容纳(164 KB)/(132 B/thread) = 1272个线程。因此，该内核的最大可实现占用率为(1272 assigned threads) / (2048 maximum threads) = 62%。

请注意，每个SM中的共享内存大小也会因设备而异。每一代或型号的设备在每个SM中可以有不同的共享内存数量。通常，内核希望能够根据硬件中可用的数量使用不同数量的共享内存。也就是说，我们可能希望主机代码能够动态确定共享内存的大小，并调整内核使用的共享内存量。这可以通过调用cudaGetDeviceProperties函数来实现。假设变量&devProp传递给该函数。在这种情况下，字段devProp.sharedMemPerBlock给出了每个SM中可用的共享内存量。然后程序员可以确定每个块应该使用的共享内存量。

不幸的是，图5.9和5.13中的内核不支持主机代码动态调整共享内存使用。图5.9中使用的声明将共享内存使用的大小硬编码为编译时常量：

```cuda
__shared__ float Mds[TILE_WIDTH][TILE_WIDTH];
__shared__ float Nds[TILE_WIDTH][TILE_WIDTH];
```

也就是说，Mds和Nds的大小被设置为TILE_WIDTH^2个元素，不管TILE_WIDTH的值在编译时被设置为什么。由于代码包含

```cuda
#define TILE_WIDTH 16
```

Mds和Nds都将有256个元素。如果我们想要改变Mds和Nds的大小，我们需要改变TILE_WIDTH的值并重新编译代码。内核不能在运行时轻松调整其共享内存使用情况，除非重新编译。

我们可以通过在CUDA中添加一个C extern关键字来启用这种调整，并且在声明共享内存时省略数组的大小。基于这种风格，Mds和Nds的声明需要合并为一个动态分配的数组：

```cuda
extern __shared__ float Mds_Nds[];
```

由于只有一个合并的数组，我们还需要手动定义数组的Mds部分从哪里开始，以及Nds部分从哪里开始。注意，合并后的数组是一维的。我们将需要使用基于垂直和水平索引的线性化索引来访问它。

在运行时，当我们调用内核时，我们可以根据设备查询结果动态配置每个块使用的共享内存量，并将该量作为第三个配置参数提供给内核调用。例如，修订后的内核可以以以下语句启动：

```cuda
size_t size = calculate_appropriate_SM_usage(devProp.sharedMemPerBlock,...);
matrixMulKernel<<<dimGrid, dimBlock, size>>>(Md, Nd, Pd, Width, size/2, size/2);
```

其中size_t是用于声明动态分配数据结构的大小信息的内置类型。大小以字节为单位。在我们的矩阵乘法示例中，对于一个16x16的平铺，我们有2 * 16 * 16 * 4 = 2048字节的大小来容纳Mds和Nds。我们已经省略了在运行时设置size值的计算细节，并将其留作读者的练习。

在图5.14中，我们展示了如何修改图5.9和5.11中的内核代码，以使用动态大小的共享内存用于Mds和Nds数组。将数组的每个部分的大小作为参数传入内核函数也可能很有用。在这个示例中，我们添加了两个参数：第一个参数是Mds部分的大小，第二个参数是Nds部分的大小，两者都以字节为单位。注意，在上述主机代码中，我们将size/2作为这些参数的值传递，即1024字节。通过06行和07行的赋值，内核代码的其余部分可以使用Mds和Nds作为数组的基础，并使用线性化索引来访问Mds和Nds元素。例如，而不是使用Mds[ty][tx]，将使用Mds[ty*TILE_WIDTH+tx]。



在CUDA编程中，占用率（occupancy）是一个关键概念，它指的是在GPU的流多处理器（Streaming Multiprocessors, SM）上同时运行的线程的数量。高占用率意味着更多的线程在同时执行，这有助于隐藏内存访问延迟，提高GPU的计算吞吐量。内存使用，特别是共享内存和寄存器的使用，对占用率有直接影响。

共享内存对占用率的影响
共享内存的使用限制了可以在一个SM上同时运行的线程块的数量。如果共享内存的使用超过了SM的容量，就会减少能够同时运行的线程块数量，从而降低占用率。例如，如果一个SM有64KB的共享内存，而每个线程块需要8KB的共享内存，那么该SM上最多可以同时运行8个线程块。

寄存器对占用率的影响
寄存器的使用也会影响占用率。每个线程都需要一定数量的寄存器来存储局部变量和临时数据。如果一个核心因为寄存器需求过高而无法容纳足够多的线程，那么占用率就会降低。例如，如果一个SM有65536个寄存器，而每个线程需要128个寄存器，那么该SM上最多可以同时运行512个线程。

如何优化内存使用以提高占用率
动态共享内存分配：

在CUDA核心中，可以通过在核心启动时指定动态共享内存的大小来动态分配共享内存。这允许核心根据需要使用共享内存，而不是在编译时静态分配一个固定的大小。
减少寄存器使用：

优化代码以减少每个线程所需的寄存器数量。例如，可以通过重用寄存器中的值，或者减少局部变量的数量来实现。
使用共享内存来减少全局内存访问：

通过将频繁访问的数据存储在共享内存中，可以减少对全局内存的访问次数，从而提高性能。但是，必须注意不要超出共享内存的容量。
平衡内存使用和计算需求：

在设计CUDA核心时，需要平衡内存使用和计算需求。例如，如果核心的计算强度很高，那么可能不需要太多的共享内存，因此可以将更多的资源分配给寄存器。
使用CUDA Occupancy Calculator：

NVIDIA提供了一个CUDA占用率计算器工具，可以帮助开发者计算在给定的内存使用情况下，可以达到的占用率。这个工具可以帮助开发者做出合适的内存使用决策。
总结
内存使用对CUDA程序的占用率有直接影响。合理地使用共享内存和寄存器可以提高占用率，从而提高GPU的计算吞吐量。开发者需要在内存使用和计算需求之间找到平衡点，以实现最佳的性能。通过动态分配共享内存、减少寄存器使用、以及使用CUDA占用率计算器等工具，可以有效地优化内存使用，提高占用率。