## 5.7 总结

## 执行速度与内存速度

总之，程序在现代处理器中的执行速度可能会受到内存速度的严重限制。为了充分利用 CUDA 设备的执行吞吐量，需要在内核代码中争取高计算与全局内存访问率。如果比率低，内核就受内存限制。也就是说，它的执行速度受到从内存访问操作数的速率的限制。

## CUDA内存类型及其访问

CUDA 提供对寄存器、共享内存和常量内存的访问。这些内存比全局内存小得多，但可以以更高的速度访问。有效地使用这些内存需要重新设计算法。

## 平铺策略

我们使用矩阵乘法作为示例来说明平铺，这是一种流行的策略，可以增强数据访问的局部性并实现共享内存的有效使用。在并行编程中，平铺使用屏障同步来强制多个线程在执行的每个阶段共同关注输入数据的子集，以便子集数据可以放入这些特殊的内存类型中，以实现更高的访问速度。

## 内存容量的局限性

然而，对于 CUDA 程序员来说，重要的是要意识到这些特殊类型内存的有限大小。它们的容量取决于实现。一旦超过它们的容量，它们就会限制每个 SM 中可以同时执行的线程数量，并可能对 GPU 的计算吞吐量及其容忍延迟的能力产生负面影响。

## 硬件限制的推理

开发应用程序时推理硬件限制的能力是并行编程的一个关键方面。

## 平铺算法的普遍性

虽然我们在 CUDA C 编程的背景下引入了平铺算法，但它是在几乎所有类型的并行计算系统中实现高性能的有效策略。原因是应用程序必须在数据访问中表现出局部性，以有效利用这些系统中的高速存储器。例如，在多核 CPU 系统中，数据局部性允许应用程序有效地使用片上数据缓存来减少内存访问延迟并实现高性能。这些片上数据缓存的大小也有限，需要计算来表现出局部性。因此，读者在使用其他编程模型为其他类型的并行计算系统开发并行应用程序时也会发现平铺算法很有用。

## 本章目标

本章的目标是介绍局部性、平铺和不同 CUDA 内存类型的概念。我们介绍了一个使用共享内存的平铺矩阵乘法内核。我们进一步研究了在应用平铺技术时允许任意数据维度的边界测试条件的需求。我们还简要讨论了动态大小的共享内存分配的使用，以便内核可以根据硬件能力调整每个块使用的共享内存的大小。我们没有讨论平铺中寄存器的使用。当我们在本书第二部分讨论并行算法模式时，我们将解释寄存器在平铺算法中的使用。
