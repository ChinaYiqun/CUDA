### 2.8 总结

在本章中，我们介绍了CUDA C编程模型的基本概念和核心扩展，这些是编写简单CUDA C程序的基础。我们讨论了如何使用CUDA C来开发能够利用数据并行性以加速执行的数据并行程序。以下是本章内容的总结：

#### 2.8.1 函数声明

CUDA C扩展了C语言的函数声明语法，以支持异构并行计算。通过使用`__global__`、`__device__`或`__host__`关键字，CUDA C程序员可以指示编译器生成内核函数、设备函数或主机函数。没有这些关键字的函数默认为主机函数。如果函数声明同时使用`__host__`和`__device__`，则编译器会为设备和主机生成两个版本的函数。

#### 2.8.2 内核调用和网格启动

CUDA C通过在内核函数调用周围使用执行配置参数（用`<<< >>>`包围）来扩展C函数调用语法。这些执行配置参数仅在调用内核函数以启动网格时使用。我们讨论了定义网格和每个块的维度的执行配置参数。有关内核启动扩展和其他类型的执行配置参数的更多详细信息，请参阅CUDA编程指南。

#### 2.8.3 内置（预定义）变量

CUDA内核可以访问一组内置的预定义只读变量，这些变量允许每个线程区分自身并确定要处理的数据区域。我们讨论了`threadIdx`、`blockDim`和`blockIdx`变量。在第3章中，我们将讨论更多关于使用这些变量的细节。

#### 2.8.4 运行时应用程序编程接口

CUDA支持一组API函数，为CUDA C程序提供服务。我们讨论的服务包括`cudaMalloc`、`cudaFree`和`cudaMemcpy`函数。这些函数由主机代码调用，分别用于分配设备全局内存、释放设备全局内存和代表调用程序在主机和设备之间传输数据。有关其他CUDA API函数的详细信息，请参考CUDA C编程指南。

本章的目标是介绍CUDA C的核心概念和关键的CUDA扩展，以便编写简单的CUDA C程序。本章并非对所有CUDA特性的全面描述。我们将在本书的其余部分中介绍更多的CUDA特性。然而，我们的重点将放在由这些特性支持的关键并行计算概念上。我们只会介绍我们代码示例中需要的CUDA C特性，以展示并行编程技术。通常，我们鼓励读者始终参考CUDA C编程指南，以获取更多CUDA C特性的详细信息。
