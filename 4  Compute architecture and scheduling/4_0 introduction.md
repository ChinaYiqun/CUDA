# 第1章 引言

在本章中，我们探讨了CPU和GPU在设计上的根本差异：
- CPU旨在最小化指令执行的延迟。
- GPU旨在最大限度地提高执行指令的吞吐量。

# 第2章 异构数据并行计算

## CUDA编程接口核心特性

我们学习了用于创建和调用内核以启动和执行线程的CUDA编程接口的核心特性。

# 第3章 多维网格和数据

本章介绍了多维网格和数据的概念，为理解CUDA编程中的并行计算提供了基础。

# 接下来的三章：现代GPU架构与性能优化

在接下来的三章中，我们将讨论现代GPU的架构，包括计算架构和内存架构，以及源自对这种架构的理解的性能优化技术。

# 本章：GPU计算架构

本章介绍了GPU计算架构的几个方面，这些方面对于CUDA C程序员理解和推理其内核代码的性能行为至关重要。

## 计算架构的高级视图

我们将首先展示计算架构的高级、简化视图，并探索以下概念：
- 灵活资源分配
- 块调度 
**将线程逐块分配给 SM 保证了同一块中的线程在同一 SM 上同时调度 ,块之间可以并行**
**warp 是 SM 中线程调度的单位**
        
- 占用

## 线程调度与延迟容忍

然后，我们将进入：
- 线程调度
- 延迟容忍
- 控制发散
- 同步

## GPU资源查询与内核执行估计

本章结束时，我们将描述：
- 可用于查询GPU中可用资源的API函数
- 在执行内核时帮助估计GPU占用率的工具

# 第5章 内存架构和数据局部性

重点介绍片上内存架构。

# 第6章 性能注意事项

简要介绍片外内存架构，然后详细说明整个GPU架构的各种性能注意事项。

# 结论

掌握这些概念的CUDA C程序员将有能力编写和理解高性能并行内核。p