# GPU 和 SM 的组织结构

## 透明可扩展性
GPU 被组织成 SM（Streaming Multiprocessors），SM 由共享控制逻辑和内存资源的多个核心处理块组成。当网格启动时，其块以任意顺序分配给 SM，从而导致 CUDA 应用程序的透明可扩展性。透明可扩展性有一个限制：不同块中的线程不能相互同步。

## 线程分配和执行
线程被分配给 SM 以逐块执行。一旦一个块被分配给 SM，它就被进一步划分为 warp。warp 中的线程按照 SIMD 模型执行。如果同一 warp 中的线程通过采用不同的执行路径而发散，则处理块在传递中执行这些路径，其中每个线程仅在与它所采用的路径对应的传递中处于活动状态。

## 占用和执行吞吐量
SM 分配给它的线程可能比它可以同时执行的多得多。在任何时候，SM 只执行其常驻 warp 的一小部分指令。这允许其他 warp 等待长延迟操作，而不会减慢大量处理单元的整体执行吞吐量。分配给 SM 的线程数与其可以支持的最大线程数的比率称为占用。SM 的占用率越高，它可以更好地隐藏长延迟操作。

## 资源限制
每个 CUDA 设备对每个 SM 中的可用资源量施加了潜在的不同限制。例如，每个 CUDA 设备对其每个 SM 可以容纳的块数、线程数、寄存器数和其他资源量都有限制。对于每个内核，这些资源限制中的一个或多个可以成为占用的限制因素。CUDA C 为程序员提供了在运行时查询 GPU 中可用资源的能力。